path:
    train_path: /opt/ml/code/level2_klue_nlp-level1-nlp-12/dataset/train/train_origin.csv
    test_path: /opt/ml/code/level2_klue_nlp-level1-nlp-12/dataset/test/test_data.csv
data:
    shuffle: True
    augmentation: # adea, bt 등등
    
model:
    model_name: klue/roberta-large
    saved_name: base

train:
    seed: 42
    gpus: 1
    batch_size: 16
    max_epoch: 20
    learning_rate: 4.78e-5
    logging_step: 5
    nums_folds: 5
    loss_name: focal # CrossEntropy, focal, label_smoothing, f1
    optimizer_name: AdamW
    lr_sch_use: False
    lr_decay_step: 20
    scheduler_name: StepLR # StepLR, ReduceLROnPlateau, CosineAnnealingLR
wandb:
    wandb_username: seokhee
    wandb_project: re_temp
    wandb_entity: re_et
