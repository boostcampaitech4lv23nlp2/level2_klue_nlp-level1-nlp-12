{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation : bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "#import os\n",
    "#os.chdir('./data')\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_dataset(dataset):\n",
    "    \"\"\"처음 불러온 csv 파일을 원하는 형태의 DataFrame으로 변경 시켜줍니다.\"\"\"\n",
    "    subject_entity = []\n",
    "    object_entity = []\n",
    "\n",
    "    for i, j in tqdm(zip(dataset[\"subject_entity\"], dataset[\"object_entity\"]), desc=\"preprocessing\"):\n",
    "        i = i[1:-1].split(\",\")[0].split(\":\")[1]\n",
    "        j = j[1:-1].split(\",\")[0].split(\":\")[1]\n",
    "\n",
    "        subject_entity.append(i)\n",
    "        object_entity.append(j)\n",
    "\n",
    "    out_dataset = pd.DataFrame(\n",
    "        {\n",
    "            \"id\": dataset[\"id\"],\n",
    "            \"sentence\": dataset[\"sentence\"],\n",
    "            \"subject_entity\": subject_entity,\n",
    "            \"object_entity\": object_entity,\n",
    "            \"label\": dataset[\"label\"],\n",
    "        }\n",
    "    )\n",
    "    return out_dataset\n",
    "\n",
    "\n",
    "def load_data(dataset_dir):\n",
    "    \"\"\"csv 파일을 경로에 맡게 불러 옵니다.\"\"\"\n",
    "    pd_dataset = pd.read_csv(dataset_dir)\n",
    "    dataset = preprocessing_dataset(pd_dataset)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def label_to_num(label):\n",
    "    num_label = []\n",
    "    with open(\"/opt/ml/code/dict_label_to_num.pkl\", \"rb\") as f:\n",
    "        dict_label_to_num = pickle.load(f)\n",
    "    for v in label:\n",
    "        num_label.append(dict_label_to_num[v])\n",
    "\n",
    "    return num_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessing: 32470it [00:00, 376672.76it/s]\n"
     ]
    }
   ],
   "source": [
    "train_path = '/opt/ml/dataset/train/train.csv'\n",
    "total_data = load_data(train_path)\n",
    "# total_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = total_data.sample(frac=0.9, random_state=42)\n",
    "val_data = total_data.drop(train_data.index)\n",
    "\n",
    "train_label = label_to_num(train_data[\"label\"].values)\n",
    "val_label = label_to_num(val_data[\"label\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Masked Language Model 활용 : klue/bert-base**   \n",
    "- mlm활용해서 entity 바꾸고, 데이터 증강하기 : 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmtest = train_data.copy()\n",
    "mlmtest = mlmtest.sort_values(by=[\"id\"], ascending=[True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **01. MLM test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 05:26:04.207654: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForMaskedLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 05:26:07.566648: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-02 05:26:07.567579: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForMaskedLM: ['cls.predictions.decoder.bias', 'bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForMaskedLM from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForMaskedLM from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'klue/bert-base'\n",
    "model = TFBertForMaskedLM.from_pretrained(MODEL_NAME, from_pt=True)   # from_pt=True pytorch로 학습된 모델을 텐서플로우에서 사용\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "from transformers import FillMaskPipeline\n",
    "pip = FillMaskPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def wordlist(x):\n",
    "    return x['token_str'] if type(x) == dict else wordlist(x[0])\n",
    "    \n",
    "def findEntityAndChange(data,col,e1,e2):        # data : Series\n",
    "    \n",
    "    # step01\n",
    "    mask_sent = data['sentence'].replace(e1,\"[MASK]\")           # sentence에 entity가 해당하는 부분 [MASK]로 바꾸기\n",
    "    entities = list(map(wordlist,pip(mask_sent)))           # mlm 활용해서 대체할 eneity 리스트 뽑기 : 5개\n",
    "    entities = entities[::-1]                                   # 순서 거꾸로 바꾸기(while문에서 pop() 사용하기 위해)\n",
    "    \n",
    "    while entities :\n",
    "        entity = entities.pop()                                 # score 가장 높은 단어부터 확인하기\n",
    "        if entity in ['[UNK]',')','(',',','#'] or '#' in entity or entity == e1 or entity == e2:     # sub,obj entity와 같거나 불용어 단어면 pass >> 불용어 처리할 단어 더 많을텐데 추가 수정사항에 해당\n",
    "            entity =''\n",
    "            continue\n",
    "        else :\n",
    "            break                                                  \n",
    "    # step02\n",
    "    change_sent = mask_sent.replace(\"[MASK]\",entity)            # sentence 바꾸기\n",
    "    \n",
    "    # step03\n",
    "    data['sentence'] = change_sent\n",
    "    data[col] = '\\''+entity+'\\''\n",
    "    return data                                   # Series 반환\n",
    "\n",
    "\n",
    "\n",
    "def use_mlm(dataset):       #\n",
    "    result_pd = pd.DataFrame()\n",
    "    \n",
    "    for idx, row in tqdm(dataset.iterrows(),desc=\"processig...\"):\n",
    "        #print('ind : ',row.id)\n",
    "        sub = row['subject_entity'].strip()[1:-1]\n",
    "        obj = row['object_entity'].strip()[1:-1]\n",
    "    \n",
    "        srow = findEntityAndChange(row.copy(),'subject_entity',sub,obj)\n",
    "        orow = findEntityAndChange(row.copy(),'object_entity',obj,sub)\n",
    "        \n",
    "        # 빈값처리\n",
    "        if srow.subject_entity !='':\n",
    "            result_pd = result_pd.append(pd.Series(srow), ignore_index=True)\n",
    "            \n",
    "        if orow.object_entity !='':\n",
    "            result_pd = result_pd.append(pd.Series(orow), ignore_index=True)\n",
    "    \n",
    "        \n",
    "    return result_pd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test5 = use_mlm(mlmtest)\n",
    "#test5.to_csv('/opt/ml/workspace/save_entity_mt.csv',index=False,encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **02.증강된 데이터와 원본 데이터 합치기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(dataset):\n",
    "    out_dataset = pd.DataFrame(\n",
    "            {\n",
    "                \"id\": dataset[\"id\"],\n",
    "                \"sentence\": dataset[\"sentence\"],\n",
    "                \"subject_entity\": \"{'word' : \"+dataset[\"subject_entity\"]+\", 'start_idx': 0, 'end_idx': 0, 'type': 'None'\",\n",
    "                \"object_entity\": \"{'word' : \"+dataset[\"object_entity\"]+\", 'start_idx': 0, 'end_idx': 0, 'type': 'None'\",\n",
    "                \"label\": dataset[\"label\"],\n",
    "            }\n",
    "    )\n",
    "    return out_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01. 불러오기\n",
    "en_pd = pd.read_csv('/opt/ml/dataset/train/aug_entities.csv')\n",
    "#en_pd\n",
    "train_path = '/opt/ml/dataset/train/train.csv'\n",
    "train = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02. 합치기\n",
    "re_en = reformat(en_pd)\n",
    "en_data = pd.concat([train,re_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_entity</th>\n",
       "      <th>object_entity</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey Road》에 담은 노래다.</td>\n",
       "      <td>{'word': '비틀즈', 'start_idx': 24, 'end_idx': 26, 'type': 'ORG'}</td>\n",
       "      <td>{'word': '조지 해리슨', 'start_idx': 13, 'end_idx': 18, 'type': 'PER'}</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으로 재탄생한다.</td>\n",
       "      <td>{'word': '민주평화당', 'start_idx': 19, 'end_idx': 23, 'type': 'ORG'}</td>\n",
       "      <td>{'word': '대안신당', 'start_idx': 14, 'end_idx': 17, 'type': 'ORG'}</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>K리그2에서 성적 1위를 달리고 있는 광주FC는 지난 26일 한국프로축구연맹으로부터 관중 유치 성과와 마케팅 성과를 인정받아 ‘풀 스타디움상’과 ‘플러스 스타디움상’을 수상했다.</td>\n",
       "      <td>{'word': '광주FC', 'start_idx': 21, 'end_idx': 24, 'type': 'ORG'}</td>\n",
       "      <td>{'word': '한국프로축구연맹', 'start_idx': 34, 'end_idx': 41, 'type': 'ORG'}</td>\n",
       "      <td>org:member_of</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>균일가 생활용품점 (주)아성다이소(대표 박정부)는 코로나19 바이러스로 어려움을 겪고 있는 대구광역시에 행복박스를 전달했다고 10일 밝혔다.</td>\n",
       "      <td>{'word': '아성다이소', 'start_idx': 13, 'end_idx': 17, 'type': 'ORG'}</td>\n",
       "      <td>{'word': '박정부', 'start_idx': 22, 'end_idx': 24, 'type': 'PER'}</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1967년 프로 야구 드래프트 1순위로 요미우리 자이언츠에게 입단하면서 등번호는 8번으로 배정되었다.</td>\n",
       "      <td>{'word': '요미우리 자이언츠', 'start_idx': 22, 'end_idx': 30, 'type': 'ORG'}</td>\n",
       "      <td>{'word': '1967', 'start_idx': 0, 'end_idx': 3, 'type': 'DAT'}</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90911</th>\n",
       "      <td>32465.0</td>\n",
       "      <td>한국당은 7일 오전 9시부터 오후 5시까지 진행된 원내대표 및 정책위의장 후보자 등록 마감 결과, 강석호(3선·경북 영양·영덕·봉화·울진)-이장우(재선·대전 동구), 유기준(4선·비례)-박성중(초선·서울 서초을), 김선동(재선·서울 도봉을)-김종석(초선·비례), 심재철(5선·경기 안양시동안구을)-김재원(3선·경북 상주·군위·의성·청송) 등 4개 조가 등록했다고 밝혔다.</td>\n",
       "      <td>{'word' : {'word' :  '유기준', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'</td>\n",
       "      <td>{'word' : {'word' : '비례', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'</td>\n",
       "      <td>per:employee_of</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90912</th>\n",
       "      <td>32467.0</td>\n",
       "      <td>신안군(군수 신우철)이 국토교통부에서 실시한 '2019 교통문화지수 실태조사'에서 229개 기초지자체 중 최상위 등급인 A등급을 받으면서 전국에서 가장 높은 교통안전 인식 수준을 갖고 있는 것으로 나타났다.</td>\n",
       "      <td>{'word' : {'word' : '신안군', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'</td>\n",
       "      <td>{'word' : {'word' :  '신우철', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90913</th>\n",
       "      <td>32467.0</td>\n",
       "      <td>완도군(군수 신우)이 국토교통부에서 실시한 '2019 교통문화지수 실태조사'에서 229개 기초지자체 중 최상위 등급인 A등급을 받으면서 전국에서 가장 높은 교통안전 인식 수준을 갖고 있는 것으로 나타났다.</td>\n",
       "      <td>{'word' : {'word' :  '완도군', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'</td>\n",
       "      <td>{'word' : {'word' : '신우', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90914</th>\n",
       "      <td>32469.0</td>\n",
       "      <td>칠곡군(군수 구충곤)은 17일 동면의 이장 20여 명이 코로나 19 예방을 위해 버스 승강장, 공중화장실 등 다중이용시설과 오동리 천운아파트 주변을 소독하는 방역 봉사활동을 펼쳤다고 밝혔다.</td>\n",
       "      <td>{'word' : {'word' : '칠곡군', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'</td>\n",
       "      <td>{'word' : {'word' :  '구충곤', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90915</th>\n",
       "      <td>32469.0</td>\n",
       "      <td>화순군(군수 박준)은 17일 동면의 이장 20여 명이 코로나 19 예방을 위해 버스 승강장, 공중화장실 등 다중이용시설과 오동리 천운아파트 주변을 소독하는 방역 봉사활동을 펼쳤다고 밝혔다.</td>\n",
       "      <td>{'word' : {'word' :  '화순군', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'</td>\n",
       "      <td>{'word' : {'word' : '박준', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123386 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  \\\n",
       "0          0.0   \n",
       "1          1.0   \n",
       "2          2.0   \n",
       "3          3.0   \n",
       "4          4.0   \n",
       "...        ...   \n",
       "90911  32465.0   \n",
       "90912  32467.0   \n",
       "90913  32467.0   \n",
       "90914  32469.0   \n",
       "90915  32469.0   \n",
       "\n",
       "                                                                                                                                                                                                              sentence  \\\n",
       "0                                                                                                                                                          〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey Road》에 담은 노래다.   \n",
       "1                                                                                                                                                               호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으로 재탄생한다.   \n",
       "2                                                                                                                  K리그2에서 성적 1위를 달리고 있는 광주FC는 지난 26일 한국프로축구연맹으로부터 관중 유치 성과와 마케팅 성과를 인정받아 ‘풀 스타디움상’과 ‘플러스 스타디움상’을 수상했다.   \n",
       "3                                                                                                                                       균일가 생활용품점 (주)아성다이소(대표 박정부)는 코로나19 바이러스로 어려움을 겪고 있는 대구광역시에 행복박스를 전달했다고 10일 밝혔다.   \n",
       "4                                                                                                                                                             1967년 프로 야구 드래프트 1순위로 요미우리 자이언츠에게 입단하면서 등번호는 8번으로 배정되었다.   \n",
       "...                                                                                                                                                                                                                ...   \n",
       "90911  한국당은 7일 오전 9시부터 오후 5시까지 진행된 원내대표 및 정책위의장 후보자 등록 마감 결과, 강석호(3선·경북 영양·영덕·봉화·울진)-이장우(재선·대전 동구), 유기준(4선·비례)-박성중(초선·서울 서초을), 김선동(재선·서울 도봉을)-김종석(초선·비례), 심재철(5선·경기 안양시동안구을)-김재원(3선·경북 상주·군위·의성·청송) 등 4개 조가 등록했다고 밝혔다.   \n",
       "90912                                                                                              신안군(군수 신우철)이 국토교통부에서 실시한 '2019 교통문화지수 실태조사'에서 229개 기초지자체 중 최상위 등급인 A등급을 받으면서 전국에서 가장 높은 교통안전 인식 수준을 갖고 있는 것으로 나타났다.   \n",
       "90913                                                                                               완도군(군수 신우)이 국토교통부에서 실시한 '2019 교통문화지수 실태조사'에서 229개 기초지자체 중 최상위 등급인 A등급을 받으면서 전국에서 가장 높은 교통안전 인식 수준을 갖고 있는 것으로 나타났다.   \n",
       "90914                                                                                                       칠곡군(군수 구충곤)은 17일 동면의 이장 20여 명이 코로나 19 예방을 위해 버스 승강장, 공중화장실 등 다중이용시설과 오동리 천운아파트 주변을 소독하는 방역 봉사활동을 펼쳤다고 밝혔다.   \n",
       "90915                                                                                                        화순군(군수 박준)은 17일 동면의 이장 20여 명이 코로나 19 예방을 위해 버스 승강장, 공중화장실 등 다중이용시설과 오동리 천운아파트 주변을 소독하는 방역 봉사활동을 펼쳤다고 밝혔다.   \n",
       "\n",
       "                                                                                                               subject_entity  \\\n",
       "0                                                              {'word': '비틀즈', 'start_idx': 24, 'end_idx': 26, 'type': 'ORG'}   \n",
       "1                                                            {'word': '민주평화당', 'start_idx': 19, 'end_idx': 23, 'type': 'ORG'}   \n",
       "2                                                             {'word': '광주FC', 'start_idx': 21, 'end_idx': 24, 'type': 'ORG'}   \n",
       "3                                                            {'word': '아성다이소', 'start_idx': 13, 'end_idx': 17, 'type': 'ORG'}   \n",
       "4                                                        {'word': '요미우리 자이언츠', 'start_idx': 22, 'end_idx': 30, 'type': 'ORG'}   \n",
       "...                                                                                                                       ...   \n",
       "90911  {'word' : {'word' :  '유기준', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'   \n",
       "90912   {'word' : {'word' : '신안군', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'   \n",
       "90913  {'word' : {'word' :  '완도군', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'   \n",
       "90914   {'word' : {'word' : '칠곡군', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'   \n",
       "90915  {'word' : {'word' :  '화순군', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'   \n",
       "\n",
       "                                                                                                                object_entity  \\\n",
       "0                                                           {'word': '조지 해리슨', 'start_idx': 13, 'end_idx': 18, 'type': 'PER'}   \n",
       "1                                                             {'word': '대안신당', 'start_idx': 14, 'end_idx': 17, 'type': 'ORG'}   \n",
       "2                                                         {'word': '한국프로축구연맹', 'start_idx': 34, 'end_idx': 41, 'type': 'ORG'}   \n",
       "3                                                              {'word': '박정부', 'start_idx': 22, 'end_idx': 24, 'type': 'PER'}   \n",
       "4                                                               {'word': '1967', 'start_idx': 0, 'end_idx': 3, 'type': 'DAT'}   \n",
       "...                                                                                                                       ...   \n",
       "90911    {'word' : {'word' : '비례', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'   \n",
       "90912  {'word' : {'word' :  '신우철', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'   \n",
       "90913    {'word' : {'word' : '신우', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'   \n",
       "90914  {'word' : {'word' :  '구충곤', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'   \n",
       "90915    {'word' : {'word' : '박준', 'start_idx': 0, 'end_idx': 0, 'type': 'None', 'start_idx': 0, 'end_idx': 0, 'type': 'None'   \n",
       "\n",
       "                           label     source  \n",
       "0                    no_relation  wikipedia  \n",
       "1                    no_relation   wikitree  \n",
       "2                  org:member_of   wikitree  \n",
       "3      org:top_members/employees   wikitree  \n",
       "4                    no_relation  wikipedia  \n",
       "...                          ...        ...  \n",
       "90911            per:employee_of        NaN  \n",
       "90912  org:top_members/employees        NaN  \n",
       "90913  org:top_members/employees        NaN  \n",
       "90914  org:top_members/employees        NaN  \n",
       "90915  org:top_members/employees        NaN  \n",
       "\n",
       "[123386 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en_data.to_csv('/opt/ml/dataset/train/aug_entities.csv',index=False,encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Masked Language Model 실습**   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- klue/bert-base : 한국어 BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForMaskedLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.MLM,Tokenizer**   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TFBertForMaskedLM.from_pretrained('BERT 모델 이름')을 넣으면 [MASK]라고 되어있는 단어를 맞추기 위한 마스크드 언어 모델링을 위한 구조로 BERT를 로드.\n",
    "- AutoTokenizer.from_pretrained('모델 이름') : 해당 모델이 학습되었을 당시에 사용되었던 토크나이저를 로드."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForMaskedLM: ['cls.predictions.decoder.bias', 'bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForMaskedLM from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForMaskedLM from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForMaskedLM.from_pretrained('klue/bert-base', from_pt=True)   # from_pt=True pytorch로 학습된 모델을 텐서플로우에서 사용\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.BERT 입력**   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=\n",
       "array([[   2, 4713, 2259, 3944, 6001, 2259,    4,  809,   18,    3]],\n",
       "      dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer('축구는 정말 재미있는 [MASK]다.', return_tensors='tf')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **input_ids**\n",
    "- klue/bert-base의 토크나이저를 사용하여 해당 문장을 정수 인코딩.\n",
    "- 토크나이저로 변환된 결과에서 input_ids를 통해 정수 인코딩 결과를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[   2 4713 2259 3944 6001 2259    4  809   18    3]], shape=(1, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **token_type_ids**\n",
    "- 토크나이저로 변환된 결과에서 token_type_ids를 통해서 문장을 구분하는 세그먼트 인코딩 결과를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0 0 0 0 0 0 0 0 0 0]], shape=(1, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(inputs['token_type_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **attention_mask**\n",
    "- 토크나이저로 변환된 결과에서 attention_mask를 통해서 실제 단어와 패딩 토큰을 구분하는 용도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 1 1 1 1 1 1 1 1 1]], shape=(1, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(inputs['attention_mask'])\n",
    "# 현재의 입력에서는 패딩이 없으므로 여기서는 문장 길이만큼의 1 시퀀스를 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. [MASK] 토큰 예측**   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForMaskedLM: ['cls.predictions.decoder.bias', 'bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForMaskedLM from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForMaskedLM from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForMaskedLM.from_pretrained('klue/bert-base', from_pt=True)   # from_pt=True pytorch로 학습된 모델을 텐서플로우에서 사용\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import FillMaskPipeline\n",
    "pip = FillMaskPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8963515162467957,\n",
       "  'token': 4559,\n",
       "  'token_str': '스포츠',\n",
       "  'sequence': '축구는 정말 재미있는 스포츠 다.'},\n",
       " {'score': 0.02595757506787777,\n",
       "  'token': 568,\n",
       "  'token_str': '거',\n",
       "  'sequence': '축구는 정말 재미있는 거 다.'},\n",
       " {'score': 0.010033931583166122,\n",
       "  'token': 3682,\n",
       "  'token_str': '경기',\n",
       "  'sequence': '축구는 정말 재미있는 경기 다.'},\n",
       " {'score': 0.007924363017082214,\n",
       "  'token': 4713,\n",
       "  'token_str': '축구',\n",
       "  'sequence': '축구는 정말 재미있는 축구 다.'},\n",
       " {'score': 0.007844218984246254,\n",
       "  'token': 5845,\n",
       "  'token_str': '놀이',\n",
       "  'sequence': '축구는 정말 재미있는 놀이 다.'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip('축구는 정말 재미있는 [MASK]다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Masked Language Model 활용 : klue/bert-base**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForMaskedLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForMaskedLM: ['cls.predictions.decoder.bias', 'bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForMaskedLM from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForMaskedLM from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'klue/bert-base'\n",
    "model = TFBertForMaskedLM.from_pretrained(MODEL_NAME, from_pt=True)   # from_pt=True pytorch로 학습된 모델을 텐서플로우에서 사용\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "from transformers import FillMaskPipeline\n",
    "pip = FillMaskPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '1년 후, 바이에른은 전설적인 오스트리아인 감독 에른스트 하펠이 이끄는 함부르크 SV와 DFB-포칼 결승에서 만났다.'\n",
    "s = '에른스트 하펠'\n",
    "o = '오스트리아'\n",
    "text_s = text.replace(s,\"[MASK]\")\n",
    "text_o = text.replace(o,\"[MASK]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1년 후, 바이에른은 전설적인 오스트리아인 감독 [MASK]이 이끄는 함부르크 SV와 DFB-포칼 결승에서 만났다.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4391782581806183,\n",
       "  'token': 1,\n",
       "  'token_str': '[UNK]',\n",
       "  'sequence': '1년 후, 바이에른은 전설적인 오스트리아인 감독 이 이끄는 함부르크 SV와 DFB - 포칼 결승에서 만났다.'},\n",
       " {'score': 0.07832354307174683,\n",
       "  'token': 19920,\n",
       "  'token_str': '케빈',\n",
       "  'sequence': '1년 후, 바이에른은 전설적인 오스트리아인 감독 케빈 이 이끄는 함부르크 SV와 DFB - 포칼 결승에서 만났다.'},\n",
       " {'score': 0.02716059237718582,\n",
       "  'token': 12603,\n",
       "  'token_str': '필립',\n",
       "  'sequence': '1년 후, 바이에른은 전설적인 오스트리아인 감독 필립 이 이끄는 함부르크 SV와 DFB - 포칼 결승에서 만났다.'},\n",
       " {'score': 0.02669833041727543,\n",
       "  'token': 14051,\n",
       "  'token_str': '마틴',\n",
       "  'sequence': '1년 후, 바이에른은 전설적인 오스트리아인 감독 마틴 이 이끄는 함부르크 SV와 DFB - 포칼 결승에서 만났다.'},\n",
       " {'score': 0.019449416548013687,\n",
       "  'token': 13,\n",
       "  'token_str': ')',\n",
       "  'sequence': '1년 후, 바이에른은 전설적인 오스트리아인 감독 ) 이 이끄는 함부르크 SV와 DFB - 포칼 결승에서 만났다.'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip(text_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.loc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Masked Language Model 활용 : XLM-RoBERTa**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLM-RoBERTa 토크나이저를 불러오기: https://huggingface.co/xlm-roberta-large\n",
    "from transformers import XLMRobertaTokenizer,TFBertForMaskedLM,AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'xlm-roberta-large'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = TFBertForMaskedLM.from_pretrained(MODEL_NAME, from_pt=True)   # from_pt=True pytorch로 학습된 모델을 텐서플로우에서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import FillMaskPipeline\n",
    "pip = FillMaskPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '이날 행사에는 김승남지역위원장을 비롯 우원식(전)원내대표, 송갑석광주시당위원장, 김철우보성군수, 이승옥강진군수, 박병종(전)고흥군수, 김성(전)장흥군수와 4개지역 더불어민주당 소속 도의원 9명, 군의원 31명을 포함 당직자 및 당원 3,500여명이 참석하여 성황리에 개최됐다.'\n",
    "s = '우원식'\n",
    "o = '원내대표'\n",
    "text_s = text.replace(s,\"[MASK]\")\n",
    "text_o = text.replace(o,\"[MASK]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 4.2155752453254536e-05,\n",
       "  'token': 111204,\n",
       "  'token_str': '很棒',\n",
       "  'sequence': '1년 후, 바이에른은 전설적인很棒 인 감독 에른스트 하펠이 이끄는 함부르크 SV와 DFB-포칼 결승에서 만났다..'},\n",
       " {'score': 3.8323556509567425e-05,\n",
       "  'token': 132616,\n",
       "  'token_str': 'pregleda',\n",
       "  'sequence': '1년 후, 바이에른은 전설적인 pregleda 인 감독 에른스트 하펠이 이끄는 함부르크 SV와 DFB-포칼 결승에서 만났다..'},\n",
       " {'score': 3.7428286304930225e-05,\n",
       "  'token': 81126,\n",
       "  'token_str': 'vôbec',\n",
       "  'sequence': '1년 후, 바이에른은 전설적인 vôbec 인 감독 에른스트 하펠이 이끄는 함부르크 SV와 DFB-포칼 결승에서 만났다..'},\n",
       " {'score': 3.650986036518589e-05,\n",
       "  'token': 52216,\n",
       "  'token_str': '游客',\n",
       "  'sequence': '1년 후, 바이에른은 전설적인游客 인 감독 에른스트 하펠이 이끄는 함부르크 SV와 DFB-포칼 결승에서 만났다..'},\n",
       " {'score': 3.5745335480896756e-05,\n",
       "  'token': 194305,\n",
       "  'token_str': 'రైతుల',\n",
       "  'sequence': '1년 후, 바이에른은 전설적인 రైతుల 인 감독 에른스트 하펠이 이끄는 함부르크 SV와 DFB-포칼 결승에서 만났다..'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MASK_TOKEN = tokenizer.mask_token\n",
    "pip(\"1년 후, 바이에른은 전설적인 {}인 감독 에른스트 하펠이 이끄는 함부르크 SV와 DFB-포칼 결승에서 만났다..\".format(MASK_TOKEN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Masked Language Model 활용 : klue/roberta-large**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForMaskedLM: ['roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.18.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.21.output.dense.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.19.attention.self.key.weight', 'lm_head.bias', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'lm_head.decoder.bias', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.13.attention.output.dense.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.13.intermediate.dense.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.13.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.18.attention.output.dense.weight', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.15.attention.self.value.bias', 'roberta.encoder.layer.3.output.dense.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.13.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.self.query.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.23.attention.self.key.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.15.attention.self.key.bias', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.embeddings.position_ids', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.query.weight']\n",
      "- This IS expected if you are initializing TFBertForMaskedLM from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForMaskedLM from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForMaskedLM were not initialized from the PyTorch model and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.21.attention.self.value.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.23.output.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'klue/roberta-large'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = TFBertForMaskedLM.from_pretrained(MODEL_NAME, from_pt=True)   # from_pt=True pytorch로 학습된 모델을 텐서플로우에서 사용\n",
    "from transformers import FillMaskPipeline\n",
    "pip = FillMaskPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.0002880006795749068,\n",
       "  'token': 16479,\n",
       "  'token_str': '동맥',\n",
       "  'sequence': '1년 후, 바이에른은 전설적인 오스트리아인 감독 동맥 이 이끄는 함부르크 SV와 DFB - 포칼 결승에서 만났다..'},\n",
       " {'score': 0.00024647614918649197,\n",
       "  'token': 5223,\n",
       "  'token_str': '부상',\n",
       "  'sequence': '1년 후, 바이에른은 전설적인 오스트리아인 감독 부상 이 이끄는 함부르크 SV와 DFB - 포칼 결승에서 만났다..'},\n",
       " {'score': 0.0002279666077811271,\n",
       "  'token': 731,\n",
       "  'token_str': '낳',\n",
       "  'sequence': '1년 후, 바이에른은 전설적인 오스트리아인 감독 낳 이 이끄는 함부르크 SV와 DFB - 포칼 결승에서 만났다..'},\n",
       " {'score': 0.00022247455490287393,\n",
       "  'token': 4796,\n",
       "  'token_str': '건축',\n",
       "  'sequence': '1년 후, 바이에른은 전설적인 오스트리아인 감독 건축 이 이끄는 함부르크 SV와 DFB - 포칼 결승에서 만났다..'},\n",
       " {'score': 0.00021462894801516086,\n",
       "  'token': 8305,\n",
       "  'token_str': '피고',\n",
       "  'sequence': '1년 후, 바이에른은 전설적인 오스트리아인 감독 피고 이 이끄는 함부르크 SV와 DFB - 포칼 결승에서 만났다..'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MASK_TOKEN = tokenizer.mask_token\n",
    "pip(\"1년 후, 바이에른은 전설적인 오스트리아인 감독 {}이 이끄는 함부르크 SV와 DFB-포칼 결승에서 만났다..\".format(MASK_TOKEN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('lv2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "460daaacedb28129c65ab758cd23a5a0183e369e52854b14e0ab0a12ea940b5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
